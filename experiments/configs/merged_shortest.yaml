exp:
  seed: 42
  device: "cuda"
  exp_name: "merged_shortest"
  variant: "shortest"
  debug: False
  sample_logging: True
model: 
  tokenizer_name: "meta-llama/Llama-3.2-1B-Instruct"
  model_name: "meta-llama/Llama-3.2-1B-Instruct"
  load_model: False
  load_model_path: ""
data:
  dataset_name: "mixed/merged"
  # True loads from hf through `load_dataset(dataset_name)` 
  # False loads from disk through 'datasets/{dataset_name}'
  load_hf: False
  input_columns: ["document", "article"]
  target_columns: ["summary", "highlights"]
  max_length: 2048
  train:
    id: "train"
    # subset_size: 1000
  val:
    id: "validation"
    # subset_size: 10
  test:
    id: "test"
    # subset_size: 100
peft:
  r: 8
  lora_alpha: 32
  lora_dropout: 0
training:
    output_dir: "results/"
    num_train_epochs: 1
    per_device_train_batch_size: 1
    per_device_eval_batch_size: 2
    # evaluation_strategy="epoch"  
    eval_strategy: "steps"
    # eval_strategy="steps"
    eval_steps: 50
    logging_dir: "logs/"
    logging_steps: 5
    fp16: True
    # save_strategy="epoch"
    save_strategy: "steps"
    save_steps: 50
    learning_rate: 0.00005 # 5e-5
    weight_decay: 0.01
    warmup_ratio: 0.05
    gradient_accumulation_steps: 8
    eval_accumulation_steps: 4
    dataloader_num_workers: 4